# Guide Sitemap XML et Robots.txt

## üìã Vue d'Ensemble

Le sitemap XML et le fichier robots.txt sont essentiels pour le SEO et l'indexation de votre site par les moteurs de recherche.

## üó∫Ô∏è Sitemap XML

### Qu'est-ce qu'un Sitemap ?

Un sitemap XML est un fichier qui liste toutes les pages importantes de votre site web. Il aide les moteurs de recherche √† :
- D√©couvrir toutes vos pages
- Comprendre la structure de votre site
- Indexer vos pages plus rapidement
- Comprendre la fr√©quence de mise √† jour de chaque page

### Localisation

Le sitemap est g√©n√©r√© automatiquement par Next.js √† partir de `app/sitemap.ts` et accessible √† :
- **URL** : `https://expira.io/sitemap.xml`

### Pages Incluses dans le Sitemap

| Page | URL | Priorit√© | Fr√©quence |
|------|-----|----------|-----------|
| Homepage | `/` | 1.0 | Daily |
| Pricing | `/pricing` | 0.9 | Weekly |
| Affiliate | `/affiliate` | 0.8 | Monthly |
| Contact | `/contact` | 0.7 | Monthly |
| FAQ | `/faq` | 0.7 | Monthly |
| Terms | `/terms` | 0.5 | Yearly |
| Privacy | `/privacy` | 0.5 | Yearly |
| Login | `/login` | 0.6 | Monthly |
| Register | `/register` | 0.6 | Monthly |
| Forgot Password | `/forgot-password` | 0.4 | Monthly |

### Comment V√©rifier le Sitemap

1. **Acc√©der directement** :
   ```
   https://expira.io/sitemap.xml
   ```

2. **Via Google Search Console** :
   - Allez dans [Google Search Console](https://search.google.com/search-console)
   - Ajoutez votre site
   - Allez dans "Sitemaps"
   - Ajoutez `sitemap.xml`
   - Soumettez

3. **Via la ligne de commande** :
   ```bash
   curl https://expira.io/sitemap.xml
   ```

### Mettre √† Jour le Sitemap

Le sitemap est g√©n√©r√© dynamiquement par Next.js. Pour ajouter une nouvelle page :

1. Ouvrez `app/sitemap.ts`
2. Ajoutez une nouvelle entr√©e :
   ```typescript
   {
     url: `${baseUrl}/nouvelle-page`,
     lastModified: now,
     changeFrequency: 'monthly',
     priority: 0.7,
   }
   ```
3. Red√©ployez l'application

### Priorit√©s et Fr√©quences

**Priorit√©s (0.0 - 1.0)** :
- `1.0` : Page la plus importante (homepage)
- `0.9` : Pages importantes (pricing, features)
- `0.7-0.8` : Pages secondaires importantes
- `0.5-0.6` : Pages moins importantes
- `0.4` : Pages peu importantes

**Fr√©quences** :
- `always` : Change √† chaque acc√®s
- `hourly` : Change toutes les heures
- `daily` : Change quotidiennement
- `weekly` : Change hebdomadairement
- `monthly` : Change mensuellement
- `yearly` : Change annuellement
- `never` : Ne change jamais

## ü§ñ Robots.txt

### Qu'est-ce que robots.txt ?

Le fichier robots.txt indique aux robots des moteurs de recherche quelles pages ils peuvent ou ne peuvent pas explorer.

### Localisation

Le robots.txt est g√©n√©r√© automatiquement par Next.js √† partir de `app/robots.ts` et accessible √† :
- **URL** : `https://expira.io/robots.txt`

### Configuration Actuelle

**Pages Autoris√©es** :
- ‚úÖ `/` (Homepage)
- ‚úÖ `/pricing`
- ‚úÖ `/contact`
- ‚úÖ `/affiliate`
- ‚úÖ `/faq`
- ‚úÖ `/terms`
- ‚úÖ `/privacy`
- ‚úÖ `/login`
- ‚úÖ `/register`

**Pages Bloqu√©es** :
- ‚ùå `/api/` (Toutes les routes API)
- ‚ùå `/dashboard/` (Pages priv√©es du dashboard)
- ‚ùå `/admin/` (Pages d'administration)
- ‚ùå `/reset-password` (Pages sensibles)
- ‚ùå `/forgot-password` (Pages sensibles)
- ‚ùå `/_next/` (Fichiers internes Next.js)

### Comment V√©rifier robots.txt

1. **Acc√©der directement** :
   ```
   https://expira.io/robots.txt
   ```

2. **Via la ligne de commande** :
   ```bash
   curl https://expira.io/robots.txt
   ```

3. **Tester avec Google** :
   - Utilisez [Google Search Console](https://search.google.com/search-console)
   - Allez dans "URL Inspection"
   - Testez votre robots.txt

### R√®gles par User-Agent

**Tous les robots (`*`)** :
- Acc√®s aux pages publiques
- Blocage des pages priv√©es et API

**Googlebot** :
- Acc√®s aux pages publiques importantes
- Blocage des pages d'authentification (pour √©viter le duplicate content)

**Bingbot** :
- M√™me configuration que Googlebot

## üîß Utilisation et Bonnes Pratiques

### 1. Soumettre le Sitemap √† Google

1. Allez sur [Google Search Console](https://search.google.com/search-console)
2. S√©lectionnez votre propri√©t√©
3. Allez dans "Sitemaps" dans le menu de gauche
4. Entrez `sitemap.xml`
5. Cliquez sur "Envoyer"

### 2. Soumettre le Sitemap √† Bing

1. Allez sur [Bing Webmaster Tools](https://www.bing.com/webmasters)
2. Ajoutez votre site
3. Allez dans "Sitemaps"
4. Entrez `https://expira.io/sitemap.xml`
5. Cliquez sur "Submit"

### 3. V√©rifier l'Indexation

**Google** :
```bash
# Rechercher dans Google
site:expira.io
```

**Bing** :
```bash
# Rechercher dans Bing
site:expira.io
```

### 4. Surveiller les Erreurs

**Google Search Console** :
- Allez dans "Couverture"
- V√©rifiez les erreurs d'indexation
- Corrigez les probl√®mes signal√©s

**Bing Webmaster Tools** :
- Allez dans "Index Explorer"
- V√©rifiez les pages index√©es
- Identifiez les probl√®mes

## üìä Monitoring et Analytics

### V√©rifier les Statistiques

1. **Google Search Console** :
   - Pages index√©es
   - Requ√™tes de recherche
   - Performances
   - Erreurs d'indexation

2. **Bing Webmaster Tools** :
   - Pages index√©es
   - Requ√™tes de recherche
   - Erreurs d'indexation

### Outils Utiles

- **Google Search Console** : https://search.google.com/search-console
- **Bing Webmaster Tools** : https://www.bing.com/webmasters
- **XML Sitemap Validator** : https://www.xml-sitemaps.com/validate-xml-sitemap.html
- **Robots.txt Tester** : https://www.google.com/webmasters/tools/robots-testing-tool

## üêõ D√©pannage

### Le Sitemap n'est pas accessible

1. **V√©rifier l'URL** :
   ```bash
   curl https://expira.io/sitemap.xml
   ```

2. **V√©rifier la configuration** :
   - Assurez-vous que `NEXT_PUBLIC_APP_URL` est correctement d√©fini
   - V√©rifiez que le fichier `app/sitemap.ts` existe

3. **V√©rifier les logs** :
   - Consultez les logs du serveur pour les erreurs

### Robots.txt bloque des pages importantes

1. **V√©rifier la configuration** :
   - Ouvrez `app/robots.ts`
   - V√©rifiez que les pages importantes sont dans `allow`

2. **Tester** :
   ```bash
   curl https://expira.io/robots.txt
   ```

### Pages non index√©es

1. **V√©rifier robots.txt** :
   - Assurez-vous que la page n'est pas bloqu√©e

2. **V√©rifier le sitemap** :
   - Assurez-vous que la page est dans le sitemap

3. **Demander l'indexation** :
   - Utilisez Google Search Console > URL Inspection
   - Cliquez sur "Demander l'indexation"

## üìù Checklist SEO

- [ ] Sitemap XML accessible √† `/sitemap.xml`
- [ ] Robots.txt accessible √† `/robots.txt`
- [ ] Sitemap soumis √† Google Search Console
- [ ] Sitemap soumis √† Bing Webmaster Tools
- [ ] Toutes les pages publiques dans le sitemap
- [ ] Pages priv√©es bloqu√©es dans robots.txt
- [ ] Priorit√©s correctes dans le sitemap
- [ ] Fr√©quences de mise √† jour appropri√©es
- [ ] Monitoring actif dans Search Console
- [ ] Erreurs d'indexation corrig√©es

## üöÄ Prochaines √âtapes

1. **Soumettre le sitemap** √† Google et Bing
2. **Surveiller l'indexation** dans Search Console
3. **Optimiser les priorit√©s** selon les performances
4. **Mettre √† jour r√©guli√®rement** le sitemap
5. **Corriger les erreurs** d'indexation rapidement

## üìö Ressources

- [Google Sitemaps Documentation](https://developers.google.com/search/docs/crawling-indexing/sitemaps/overview)
- [Robots.txt Specification](https://www.robotstxt.org/)
- [Next.js Sitemap Documentation](https://nextjs.org/docs/app/api-reference/file-conventions/metadata/sitemap)
- [Next.js Robots Documentation](https://nextjs.org/docs/app/api-reference/file-conventions/metadata/robots)

